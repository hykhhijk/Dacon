{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5096,
        "step_number": 1,
        "trusted": true
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "path = \"/mnt/d/data/accident/\"\n",
        "\n",
        "train_org = pd.read_csv(path + 'train.csv') \n",
        "test_org = pd.read_csv(path + 'test.csv')\n",
        "\n",
        "sample_submission = pd.read_csv(path+\"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5096,
        "step_number": 1,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5096,
        "step_number": 1,
        "trusted": true
      },
      "source": [
        "## train, test 데이터 기간 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5096,
        "step_number": 1,
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'train : 2019-01-01 00 ~ 2021-12-31 23'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'test : 2022-01-01 01 ~ 2022-12-31 21'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(f\"train : {train_org.iloc[0]['사고일시']} ~ {train_org.iloc[-1]['사고일시']}\")\n",
        "display(f\"test : {test_org.iloc[0]['사고일시']} ~ {test_org.iloc[-1]['사고일시']}\")     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5168,
        "step_number": 2,
        "trusted": true
      },
      "source": [
        "# **데이터 전처리**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5168,
        "step_number": 2,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df = train_org.copy()\n",
        "test_df = test_org.copy()\n",
        "\n",
        "time_pattern = r'(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d{1,2})' \n",
        "\n",
        "train_df[['연', '월', '일', '시간']] = train_org['사고일시'].str.extract(time_pattern)\n",
        "train_df[['연', '월', '일', '시간']] = train_df[['연', '월', '일', '시간']].apply(pd.to_numeric) # 추출된 문자열을 수치화해줍니다 \n",
        "train_df = train_df.drop(columns=['사고일시']) # 정보 추출이 완료된 '사고일시' 컬럼은 제거합니다 \n",
        "\n",
        "# 해당 과정을 test_x에 대해서도 반복해줍니다 \n",
        "test_df[['연', '월', '일', '시간']] = test_org['사고일시'].str.extract(time_pattern)\n",
        "test_df[['연', '월', '일', '시간']] = test_df[['연', '월', '일', '시간']].apply(pd.to_numeric)\n",
        "test_df = test_df.drop(columns=['사고일시'])\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "train_df[['도시', '구', '동']] = train_org['시군구'].str.extract(location_pattern)\n",
        "train_df = train_df.drop(columns=['시군구'])\n",
        "\n",
        "test_df[['도시', '구', '동']] = test_org['시군구'].str.extract(location_pattern)\n",
        "test_df = test_df.drop(columns=['시군구'])\n",
        "\n",
        "road_pattern = r'(.+) - (.+)'\n",
        "\n",
        "train_df[['도로형태1', '도로형태2']] = train_org['도로형태'].str.extract(road_pattern)\n",
        "train_df = train_df.drop(columns=['도로형태'])\n",
        "\n",
        "test_df[['도로형태1', '도로형태2']] = test_org['도로형태'].str.extract(road_pattern)\n",
        "test_df = test_df.drop(columns=['도로형태'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use additional data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_647/3027470451.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  light_df = pd.read_csv(os.path.join(path, \"external_open/light.csv\"), encoding='cp949')[['설치개수', '소재지지번주소']]\n"
          ]
        }
      ],
      "source": [
        "light_df = pd.read_csv(os.path.join(path, \"external_open/light.csv\"), encoding='cp949')[['설치개수', '소재지지번주소']]\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "light_df[['도시', '구', '동', '번지']] = light_df['소재지지번주소'].str.extract(location_pattern)\n",
        "light_df = light_df.drop(columns=['소재지지번주소', '번지'])\n",
        "\n",
        "light_df = light_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
        "light_df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "child_area_df = pd.read_csv(os.path.join(path, \"external_open/child.csv\"), encoding='cp949')[['CCTV설치대수', '소재지지번주소']]\n",
        "child_area_df['보호구역수'] = 1\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "child_area_df[['도시', '구', '동', '번지']] = child_area_df['소재지지번주소'].str.extract(location_pattern)\n",
        "child_area_df = child_area_df.drop(columns=['소재지지번주소', '번지'])\n",
        "\n",
        "child_area_df = child_area_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
        "child_area_df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "parking_df = pd.read_csv(os.path.join(path, \"external_open/parking.csv\"), encoding='cp949')[['소재지지번주소', '급지구분', \"주차구획수\"]]\n",
        "parking_df = pd.get_dummies(parking_df, columns=['급지구분'])\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "parking_df[['도시', '구', '동', '번지']] = parking_df['소재지지번주소'].str.extract(location_pattern)\n",
        "parking_df = parking_df.drop(columns=['소재지지번주소', '번지'])\n",
        "\n",
        "parking_df = parking_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
        "parking_df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge with original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.merge(train_df, light_df, how='left', on=['도시', '구', '동'])\n",
        "train_df = pd.merge(train_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
        "train_df = pd.merge(train_df, parking_df, how='left', on=['도시', '구', '동'])\n",
        "\n",
        "test_df = pd.merge(test_df, light_df, how='left', on=['도시', '구', '동'])\n",
        "test_df = pd.merge(test_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
        "test_df = pd.merge(test_df, parking_df, how='left', on=['도시', '구', '동'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5173,
        "step_number": 7,
        "trusted": true
      },
      "source": [
        "## Drop labels not included in test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5173,
        "step_number": 7,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_x = test_df.drop(columns=['ID']).copy()\n",
        "train_x = train_df[test_x.columns].copy()\n",
        "train_y = train_df['ECLO'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5174,
        "step_number": 8,
        "trusted": true
      },
      "source": [
        "## **범주형(Categorical) 변수, 수치형 변수로 변환하기**\n",
        "\n",
        "모델 학습을 위해 train_x의 문자열 타입의 컬럼들을 추출하고, LabelEncoder를 활용하여 이 컬럼들을 모두 수치형 변수로 변환해 보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5174,
        "step_number": 8,
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['요일', '기상상태', '노면상태', '사고유형', '도시', '구', '동', '도로형태1', '도로형태2']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "categorical_features = list(train_x.dtypes[train_x.dtypes == \"object\"].index)\n",
        "# 추출된 문자열 변수 확인\n",
        "display(categorical_features)\n",
        "\n",
        "for i in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    le=le.fit(train_x[i]) \n",
        "    train_x[i]=le.transform(train_x[i])\n",
        "    \n",
        "    test_x[i]=le.transform(test_x[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x.fillna(0, inplace=True)\n",
        "test_x.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5176,
        "step_number": 10,
        "trusted": true
      },
      "source": [
        "# Model Train & Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        super(CustomDataset, self).__init__()\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        # 텐서 변환\n",
        "        self.x = torch.tensor(self.x.values).float()\n",
        "        self.y = torch.tensor(self.y).float()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x[idx]\n",
        "        y = self.y[idx]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = CustomDataset(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rmsle(pred, target):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()\n",
        "    loss = torch.square(torch.log1p(pred) - torch.log1p(target))\n",
        "\n",
        "    return(torch.sqrt(loss.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_fn(pred, target):\n",
        "    return rmsle(pred, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version:[1.13.1+cu117].\n",
            "device:[cuda:0].\n"
          ]
        }
      ],
      "source": [
        "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print (\"device:[%s].\"%(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DenseModel(nn.Module):\n",
        "    def __init__(self, input_dim = 10):\n",
        "        super(DenseModel, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "\n",
        "        self.layers = []\n",
        "        self.layers.append(nn.BatchNorm1d(input_dim))\n",
        "        self.layers.append(nn.Linear(input_dim, 16, bias=True))\n",
        "        self.layers.append(nn.ReLU(True))\n",
        "        self.layers.append(nn.Linear(16, 32, bias=True))\n",
        "        self.layers.append(nn.ReLU(True))\n",
        "        self.layers.append(nn.Linear(32, 1, bias=True))\n",
        "\n",
        "        self.net = nn.Sequential(*self.layers)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.net(x)     \n",
        "    \n",
        "model = DenseModel(len(train_x.columns)).to(device)\n",
        "optm = optim.Adam(model.parameters(),lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 20])\n",
            "torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "x, y = next(iter(dataloader))\n",
        "print(x.shape)\n",
        "value = model.forward(x)\n",
        "print(value.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "00000 loss = 0.50183\n",
            "00020 loss = 0.44822\n",
            "00040 loss = 0.44800\n",
            "00060 loss = 0.44790\n",
            "00080 loss = 0.44780\n",
            "00100 loss = 0.44805\n",
            "00120 loss = 0.44741\n",
            "00140 loss = 0.44772\n",
            "00160 loss = 0.44802\n",
            "00180 loss = 0.44811\n",
            "------------------------------------------------------------\n",
            "00199 loss = 0.44776\n"
          ]
        }
      ],
      "source": [
        "# 최대 반복 횟수 정의\n",
        "num_epoch = 200\n",
        "# loss 기록하기 위한 list 정의\n",
        "losses = []\n",
        "for epoch in range(num_epoch):\n",
        "    # loss 초기화\n",
        "    running_loss = 0\n",
        "    for x, y in dataloader:\n",
        "        # x, y 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "    \n",
        "        # 그라디언트 초기화 (초기화를 수행하지 않으면 계산된 그라디언트는 누적됩니다.)\n",
        "        optm.zero_grad()\n",
        "\n",
        "        # output 계산: model의 __call__() 함수 호출\n",
        "        y_hat =  model(x)\n",
        "\n",
        "        # 손실(loss) 계산\n",
        "        loss = loss_fn(y, y_hat)\n",
        "\n",
        "        # 미분 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 경사하강법 계산 및 적용\n",
        "        optm.step()\n",
        "\n",
        "        # 배치별 loss 를 누적합산 합니다.\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    # 누적합산된 배치별 loss값을 배치의 개수로 나누어 Epoch당 loss를 산출합니다.\n",
        "    loss = running_loss / len(dataloader)\n",
        "    losses.append(loss)\n",
        "\n",
        "    # 20번의 Epcoh당 출력합니다.\n",
        "    if epoch % 20 == 0:\n",
        "        print(\"{0:05d} loss = {1:.5f}\".format(epoch, loss))\n",
        "    \n",
        "print(\"----\" * 15)\n",
        "print(\"{0:05d} loss = {1:.5f}\".format(epoch, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, x):\n",
        "        super(TestDataset, self).__init__()\n",
        "        self.x = x\n",
        "        # 텐서 변환\n",
        "        self.x = torch.tensor(self.x.values).float()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x[idx]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "testset = TestDataset(test_x)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in testloader:\n",
        "        batch_in = batch.to(device)\n",
        "        pred = model(batch_in)\n",
        "\n",
        "        predictions.append(pred.cpu().numpy())\n",
        "all_predictions = np.concatenate(predictions, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[4.058453],\n",
              "       [4.058453],\n",
              "       [4.058453],\n",
              "       ...,\n",
              "       [4.058453],\n",
              "       [4.058453],\n",
              "       [4.058453]], dtype=float32)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4.058453], dtype=float32)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(all_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5178,
        "step_number": 12,
        "trusted": true
      },
      "source": [
        "## **Submission 양식 확인**\n",
        "\n",
        "sample_submission.csv 화일 데이터(sample_submission)를 그대로 복사한 후, \n",
        "양식의 'ECLO' 컬럼에 test_x에 대한 ECLO(y) 예측값을 입력합니다 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5178,
        "step_number": 12,
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>ECLO</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ACCIDENT_39609</td>\n",
              "      <td>4.058453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ACCIDENT_39610</td>\n",
              "      <td>4.058453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ACCIDENT_39611</td>\n",
              "      <td>4.058453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ACCIDENT_39612</td>\n",
              "      <td>4.058453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACCIDENT_39613</td>\n",
              "      <td>4.058453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10958</th>\n",
              "      <td>ACCIDENT_50567</td>\n",
              "      <td>4.058453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10959</th>\n",
              "      <td>ACCIDENT_50568</td>\n",
              "      <td>4.058453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10960</th>\n",
              "      <td>ACCIDENT_50569</td>\n",
              "      <td>4.058453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10961</th>\n",
              "      <td>ACCIDENT_50570</td>\n",
              "      <td>4.058453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10962</th>\n",
              "      <td>ACCIDENT_50571</td>\n",
              "      <td>4.058453</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10963 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ID      ECLO\n",
              "0      ACCIDENT_39609  4.058453\n",
              "1      ACCIDENT_39610  4.058453\n",
              "2      ACCIDENT_39611  4.058453\n",
              "3      ACCIDENT_39612  4.058453\n",
              "4      ACCIDENT_39613  4.058453\n",
              "...               ...       ...\n",
              "10958  ACCIDENT_50567  4.058453\n",
              "10959  ACCIDENT_50568  4.058453\n",
              "10960  ACCIDENT_50569  4.058453\n",
              "10961  ACCIDENT_50570  4.058453\n",
              "10962  ACCIDENT_50571  4.058453\n",
              "\n",
              "[10963 rows x 2 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_submission = sample_submission.copy()\n",
        "baseline_submission['ECLO'] = all_predictions\n",
        "baseline_submission "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5178,
        "step_number": 12,
        "trusted": true
      },
      "source": [
        "## **답안지 저장 및 제출하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5178,
        "step_number": 12,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "baseline_submission.to_csv('baseline_submit.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
