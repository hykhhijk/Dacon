{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5096,
        "step_number": 1,
        "trusted": true
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "path = \"/mnt/d/data/accident/\"\n",
        "\n",
        "train_org = pd.read_csv(path + 'train.csv') \n",
        "test_org = pd.read_csv(path + 'test.csv')\n",
        "\n",
        "sample_submission = pd.read_csv(path+\"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5096,
        "step_number": 1,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5096,
        "step_number": 1,
        "trusted": true
      },
      "source": [
        "## train, test 데이터 기간 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5096,
        "step_number": 1,
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'train : 2019-01-01 00 ~ 2021-12-31 23'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'test : 2022-01-01 01 ~ 2022-12-31 21'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(f\"train : {train_org.iloc[0]['사고일시']} ~ {train_org.iloc[-1]['사고일시']}\")\n",
        "display(f\"test : {test_org.iloc[0]['사고일시']} ~ {test_org.iloc[-1]['사고일시']}\")     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5168,
        "step_number": 2,
        "trusted": true
      },
      "source": [
        "# **데이터 전처리**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5168,
        "step_number": 2,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df = train_org.copy()\n",
        "test_df = test_org.copy()\n",
        "\n",
        "time_pattern = r'(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d{1,2})' \n",
        "\n",
        "train_df[['연', '월', '일', '시간']] = train_org['사고일시'].str.extract(time_pattern)\n",
        "train_df[['연', '월', '일', '시간']] = train_df[['연', '월', '일', '시간']].apply(pd.to_numeric) # 추출된 문자열을 수치화해줍니다 \n",
        "train_df = train_df.drop(columns=['사고일시']) # 정보 추출이 완료된 '사고일시' 컬럼은 제거합니다 \n",
        "\n",
        "# 해당 과정을 test_x에 대해서도 반복해줍니다 \n",
        "test_df[['연', '월', '일', '시간']] = test_org['사고일시'].str.extract(time_pattern)\n",
        "test_df[['연', '월', '일', '시간']] = test_df[['연', '월', '일', '시간']].apply(pd.to_numeric)\n",
        "test_df = test_df.drop(columns=['사고일시'])\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "train_df[['도시', '구', '동']] = train_org['시군구'].str.extract(location_pattern)\n",
        "train_df = train_df.drop(columns=['시군구'])\n",
        "\n",
        "test_df[['도시', '구', '동']] = test_org['시군구'].str.extract(location_pattern)\n",
        "test_df = test_df.drop(columns=['시군구'])\n",
        "\n",
        "road_pattern = r'(.+) - (.+)'\n",
        "\n",
        "train_df[['도로형태1', '도로형태2']] = train_org['도로형태'].str.extract(road_pattern)\n",
        "train_df = train_df.drop(columns=['도로형태'])\n",
        "\n",
        "test_df[['도로형태1', '도로형태2']] = test_org['도로형태'].str.extract(road_pattern)\n",
        "test_df = test_df.drop(columns=['도로형태'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use additional data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_738/3027470451.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  light_df = pd.read_csv(os.path.join(path, \"external_open/light.csv\"), encoding='cp949')[['설치개수', '소재지지번주소']]\n"
          ]
        }
      ],
      "source": [
        "light_df = pd.read_csv(os.path.join(path, \"external_open/light.csv\"), encoding='cp949')[['설치개수', '소재지지번주소']]\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "light_df[['도시', '구', '동', '번지']] = light_df['소재지지번주소'].str.extract(location_pattern)\n",
        "light_df = light_df.drop(columns=['소재지지번주소', '번지'])\n",
        "\n",
        "light_df = light_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
        "light_df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "child_area_df = pd.read_csv(os.path.join(path, \"external_open/child.csv\"), encoding='cp949')[['CCTV설치대수', '소재지지번주소']]\n",
        "child_area_df['보호구역수'] = 1\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "child_area_df[['도시', '구', '동', '번지']] = child_area_df['소재지지번주소'].str.extract(location_pattern)\n",
        "child_area_df = child_area_df.drop(columns=['소재지지번주소', '번지'])\n",
        "\n",
        "child_area_df = child_area_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
        "child_area_df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "parking_df = pd.read_csv(os.path.join(path, \"external_open/parking.csv\"), encoding='cp949')[['소재지지번주소', '급지구분', \"주차구획수\"]]\n",
        "parking_df = pd.get_dummies(parking_df, columns=['급지구분'])\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "parking_df[['도시', '구', '동', '번지']] = parking_df['소재지지번주소'].str.extract(location_pattern)\n",
        "parking_df = parking_df.drop(columns=['소재지지번주소', '번지'])\n",
        "\n",
        "parking_df = parking_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
        "parking_df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "추가 정보 적기\n",
        "1. 원핫 인코딩(\"구\" 열에 대하여)\n",
        "2. 시군구 사고횟수 추가\n",
        "3. 휴일 변수 추가\n",
        "4. 계절 변수 추가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge with original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.merge(train_df, light_df, how='left', on=['도시', '구', '동'])\n",
        "train_df = pd.merge(train_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
        "train_df = pd.merge(train_df, parking_df, how='left', on=['도시', '구', '동'])\n",
        "\n",
        "test_df = pd.merge(test_df, light_df, how='left', on=['도시', '구', '동'])\n",
        "test_df = pd.merge(test_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
        "test_df = pd.merge(test_df, parking_df, how='left', on=['도시', '구', '동'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use additional data(1206)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### add accident num col "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "accident_cnt_m = train_df[\"구\"].value_counts()\n",
        "accident_cnt_s = train_df[\"동\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df = train_df.copy()\n",
        "temp_testdf = test_df.copy()\n",
        "\n",
        "\n",
        "temp_df['사고발생횟수_구'] = train_df['구'].apply(lambda x:accident_cnt_m[x])\n",
        "temp_df['사고발생횟수_동'] = train_df['동'].apply(lambda x:accident_cnt_s[x])\n",
        "\n",
        "temp_testdf['사고발생횟수_구'] = train_df['구'].apply(lambda x:accident_cnt_m[x])\n",
        "temp_testdf['사고발생횟수_동'] = train_df['동'].apply(lambda x:accident_cnt_s[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['사고발생횟수_구'] = train_df['구'].apply(lambda x:accident_cnt_m[x])\n",
        "train_df['사고발생횟수_동'] = train_df['동'].apply(lambda x:accident_cnt_s[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## add holiday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_org['사고일시'] = pd.to_datetime(train_org['사고일시'])\n",
        "test_org['사고일시'] = pd.to_datetime(test_org['사고일시'])\n",
        "\n",
        "# datetime을 여러 파생 변수로 변환\n",
        "for df in [train_org, test_org]:\n",
        "    df['year'] = df['사고일시'].dt.year\n",
        "    df['month'] = df['사고일시'].dt.month\n",
        "    df['day'] = df['사고일시'].dt.day\n",
        "    df['hour'] = df['사고일시'].dt.hour\n",
        "    df['minute'] = df['사고일시'].dt.minute\n",
        "    df['weekday'] = df['사고일시'].dt.weekday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "holi_weekday = ['2019-01-01', '2019-02-04', '2019-02-05', '2019-02-06', '2019-03-01', '2019-05-05', '2019-05-12', '2019-06-06', '2019-08-15', '2019-09-12', '2019-09-13', '2019-09-14', '2019-10-03', '2019-10-09', '2019-12-25',\n",
        "                '2020-01-01' ,'2020-01-24' ,'2020-01-25', '2020-01-26', '2020-03-01', '2020-04-30', '2020-05-05', '2020-06-06', '2020-08-15', '2020-08-17', '2020-09-30', '2020-10-01', '2020-10-02', '2020-10-03', '2020-10-09', '2020-12-25',\n",
        "                '2021-01-01' ,'2021-02-11' ,'2021-02-12', '2021-02-13', '2021-03-01', '2021-05-05', '2021-05-19', '2021-06-06', '2021-08-15', '2021-09-20', '2021-09-21', '2021-09-22', '2021-10-03', '2021-10-09', '2021-12-25',\n",
        "                '2022-01-01' ,'2022-01-31' ,'2022-02-01', '2022-02-02', '2022-03-01', '2022-05-05', '2022-05-08', '2022-06-06', '2022-08-15', '2022-09-09', '2022-09-10', '2022-09-11', '2022-09-12', '2022-10-03', '2022-10-09', '2020-10-10', '2022-12-25',\n",
        "                '2023-01-01' ,'2023-01-21' ,'2023-01-22', '2023-01-23', '2023-01-24', '2023-03-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_org['사고일시'] = pd.to_datetime(train_org['사고일시'])\n",
        "train_org['day_of_week'] = train_org['사고일시'].dt.dayofweek\n",
        "train_org['holiday'] = np.where((train_org.day_of_week >= 5) | (train_org.사고일시.dt.strftime('%Y-%m-%d').isin(holi_weekday)), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_org['사고일시'] = pd.to_datetime(test_org['사고일시'])\n",
        "test_org['day_of_week'] = test_org['사고일시'].dt.dayofweek\n",
        "test_org['holiday'] = np.where((test_org.day_of_week >= 5) | (test_org.사고일시.dt.strftime('%Y-%m-%d').isin(holi_weekday)), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_df = train_df.copy()\n",
        "temp_testdf = test_df.copy()\n",
        "\n",
        "temp_df[\"holiday\"] = train_org['holiday']\n",
        "temp_testdf[\"holiday\"] = test_org[\"holiday\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['요일', '기상상태', '노면상태', '사고유형', '도시', '구', '동', '도로형태1', '도로형태2']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_x = test_df.drop(columns=['ID']).copy()\n",
        "train_x = train_df[test_x.columns].copy()\n",
        "train_y = train_df['ECLO'].copy()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "categorical_features = list(train_x.dtypes[train_x.dtypes == \"object\"].index)\n",
        "# 추출된 문자열 변수 확인\n",
        "display(categorical_features)\n",
        "\n",
        "for i in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    le=le.fit(train_x[i]) \n",
        "    train_x[i]=le.transform(train_x[i])\n",
        "    \n",
        "    test_x[i]=le.transform(test_x[i])\n",
        "\n",
        "train_x.fillna(0, inplace=True)\n",
        "test_x.fillna(0, inplace=True)\n",
        "    \n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_x, train_y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rmsle(pred, target):\n",
        "    loss = np.square(np.log1p(pred) - np.log1p(target))\n",
        "    return(np.sqrt(loss.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4868872793940514\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_valid)\n",
        "print(rmsle(pred, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "요일 0.0685\n",
            "기상상태 0.0151\n",
            "노면상태 0.0112\n",
            "사고유형 0.022\n",
            "연 0.0472\n",
            "월 0.1272\n",
            "일 0.1812\n",
            "시간 0.1516\n",
            "도시 0.0\n",
            "구 0.0254\n",
            "동 0.0793\n",
            "도로형태1 0.0199\n",
            "도로형태2 0.0438\n",
            "설치개수 0.0574\n",
            "CCTV설치대수 0.0148\n",
            "보호구역수 0.0266\n",
            "주차구획수 0.0499\n",
            "급지구분_1 0.013\n",
            "급지구분_2 0.0191\n",
            "급지구분_3 0.0267\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(train_x.columns)):\n",
        "    print(train_x.columns[i], round(model.feature_importances_[i], 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['요일', '기상상태', '노면상태', '사고유형', '도시', '구', '동', '도로형태1', '도로형태2']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_x = temp_testdf.drop(columns=['ID']).copy()\n",
        "train_x = temp_df[test_x.columns].copy()\n",
        "train_y = temp_df['ECLO'].copy()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "categorical_features = list(train_x.dtypes[train_x.dtypes == \"object\"].index)\n",
        "# 추출된 문자열 변수 확인\n",
        "display(categorical_features)\n",
        "\n",
        "for i in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    le=le.fit(train_x[i]) \n",
        "    train_x[i]=le.transform(train_x[i])\n",
        "    \n",
        "    test_x[i]=le.transform(test_x[i])\n",
        "\n",
        "train_x.fillna(0, inplace=True)\n",
        "test_x.fillna(0, inplace=True)\n",
        "    \n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_x, train_y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.48428290540643765\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_valid)\n",
        "print(rmsle(pred, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "요일 0.0743\n",
            "기상상태 0.0155\n",
            "노면상태 0.0117\n",
            "사고유형 0.0225\n",
            "연 0.0381\n",
            "월 0.1279\n",
            "일 0.182\n",
            "시간 0.1521\n",
            "도시 0.0\n",
            "구 0.0157\n",
            "동 0.058\n",
            "도로형태1 0.0207\n",
            "도로형태2 0.0442\n",
            "설치개수 0.0421\n",
            "CCTV설치대수 0.0121\n",
            "보호구역수 0.0209\n",
            "주차구획수 0.0379\n",
            "급지구분_1 0.0102\n",
            "급지구분_2 0.016\n",
            "급지구분_3 0.0233\n",
            "사고발생횟수_구 0.0168\n",
            "사고발생횟수_동 0.0579\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(train_x.columns)):\n",
        "    print(train_x.columns[i], round(model.feature_importances_[i], 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_738/471982855.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  train_org.corr()[\"ECLO\"].sort_values(ascending=False)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ECLO           1.000000\n",
              "경상자수           0.636370\n",
              "중상자수           0.464520\n",
              "사망자수           0.218507\n",
              "holiday        0.060091\n",
              "weekday        0.039407\n",
              "day_of_week    0.039407\n",
              "month         -0.006871\n",
              "day           -0.012303\n",
              "hour          -0.017355\n",
              "year          -0.031281\n",
              "부상자수          -0.118713\n",
              "minute              NaN\n",
              "Name: ECLO, dtype: float64"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_org.corr()[\"ECLO\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5173,
        "step_number": 7,
        "trusted": true
      },
      "source": [
        "## Drop labels not included in test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5173,
        "step_number": 7,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_x = test_df.drop(columns=['ID']).copy()\n",
        "train_x = train_df[test_x.columns].copy()\n",
        "train_y = train_df['ECLO'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5174,
        "step_number": 8,
        "trusted": true
      },
      "source": [
        "## **범주형(Categorical) 변수, 수치형 변수로 변환하기**\n",
        "\n",
        "모델 학습을 위해 train_x의 문자열 타입의 컬럼들을 추출하고, LabelEncoder를 활용하여 이 컬럼들을 모두 수치형 변수로 변환해 보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5174,
        "step_number": 8,
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['요일', '기상상태', '노면상태', '사고유형', '도시', '구', '동', '도로형태1', '도로형태2']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "categorical_features = list(train_x.dtypes[train_x.dtypes == \"object\"].index)\n",
        "# 추출된 문자열 변수 확인\n",
        "display(categorical_features)\n",
        "\n",
        "for i in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    le=le.fit(train_x[i]) \n",
        "    train_x[i]=le.transform(train_x[i])\n",
        "    \n",
        "    test_x[i]=le.transform(test_x[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x.fillna(0, inplace=True)\n",
        "test_x.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5176,
        "step_number": 10,
        "trusted": true
      },
      "source": [
        "# Model Train & Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5176,
        "step_number": 10,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor() \n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "prediction = model.predict(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20231127_133048\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20231127_133048\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.13\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct 5 21:02:42 UTC 2023\n",
            "Disk Space Avail:   1938.07 GB / 2000.40 GB (96.9%)\n",
            "Train Data Rows:    39609\n",
            "Train Data Columns: 20\n",
            "Label Column: label\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10158.44 MB\n",
            "\tTrain Data (Original)  Memory Usage: 6.34 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['도시']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) :  7 | ['설치개수', 'CCTV설치대수', '보호구역수', '주차구획수', '급지구분_1', ...]\n",
            "\t\t('int', [])   : 12 | ['요일', '기상상태', '노면상태', '사고유형', '연', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) :  7 | ['설치개수', 'CCTV설치대수', '보호구역수', '주차구획수', '급지구분_1', ...]\n",
            "\t\t('int', [])   : 12 | ['요일', '기상상태', '노면상태', '사고유형', '연', ...]\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 6.02 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.08s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.06311696836577546, Train Rows: 37108, Val Rows: 2501\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-3.5039\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-3.5717\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-3.1715\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.57s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-3.1619\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.18s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-3.2732\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.89s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "/home/hykhhijk/anaconda3/envs/ag/lib/python3.10/site-packages/catboost/core.py:1222: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  self._init_pool(data, label, cat_features, text_features, embedding_features, pairs, weight,\n",
            "\t-3.1547\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-3.2871\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.41s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 9: early stopping\n",
            "\t-3.1687\t = Validation score   (-root_mean_squared_error)\n",
            "\t15.78s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-3.1621\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-3.2032\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.73s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-3.1741\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.35s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-3.1542\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.15s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 36.32s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231127_133048\")\n"
          ]
        }
      ],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "train_x = TabularDataset(train_x)\n",
        "train_x[\"label\"] = train_y\n",
        "predictor = TabularPredictor(label=\"label\", eval_metric=\"root_mean_squared_error\", problem_type=\"regression\").fit(train_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2  -3.154248       0.101439  19.812445                0.000222           0.146062            2       True         12\n",
            "1              CatBoost  -3.154663       0.001944   0.615816                0.001944           0.615816            1       True          6\n",
            "2              LightGBM  -3.161942       0.001652   0.176849                0.001652           0.176849            1       True          4\n",
            "3               XGBoost  -3.162130       0.004154   0.377868                0.004154           0.377868            1       True          9\n",
            "4       NeuralNetFastAI  -3.168732       0.018366  15.781750                0.018366          15.781750            1       True          8\n",
            "5            LightGBMXT  -3.171463       0.002525   0.572522                0.002525           0.572522            1       True          3\n",
            "6         LightGBMLarge  -3.174114       0.001978   0.354304                0.001978           0.354304            1       True         11\n",
            "7        NeuralNetTorch  -3.203236       0.008327  11.732957                0.008327          11.732957            1       True         10\n",
            "8       RandomForestMSE  -3.273199       0.076752   2.890948                0.076752           2.890948            1       True          5\n",
            "9         ExtraTreesMSE  -3.287109       0.066056   1.411693                0.066056           1.411693            1       True          7\n",
            "10       KNeighborsUnif  -3.503884       0.168962   0.045144                0.168962           0.045144            1       True          1\n",
            "11       KNeighborsDist  -3.571683       0.063752   0.028888                0.063752           0.028888            1       True          2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>-3.154248</td>\n",
              "      <td>0.101439</td>\n",
              "      <td>19.812445</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.146062</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>-3.154663</td>\n",
              "      <td>0.001944</td>\n",
              "      <td>0.615816</td>\n",
              "      <td>0.001944</td>\n",
              "      <td>0.615816</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>-3.161942</td>\n",
              "      <td>0.001652</td>\n",
              "      <td>0.176849</td>\n",
              "      <td>0.001652</td>\n",
              "      <td>0.176849</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>-3.162130</td>\n",
              "      <td>0.004154</td>\n",
              "      <td>0.377868</td>\n",
              "      <td>0.004154</td>\n",
              "      <td>0.377868</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NeuralNetFastAI</td>\n",
              "      <td>-3.168732</td>\n",
              "      <td>0.018366</td>\n",
              "      <td>15.781750</td>\n",
              "      <td>0.018366</td>\n",
              "      <td>15.781750</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>-3.171463</td>\n",
              "      <td>0.002525</td>\n",
              "      <td>0.572522</td>\n",
              "      <td>0.002525</td>\n",
              "      <td>0.572522</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LightGBMLarge</td>\n",
              "      <td>-3.174114</td>\n",
              "      <td>0.001978</td>\n",
              "      <td>0.354304</td>\n",
              "      <td>0.001978</td>\n",
              "      <td>0.354304</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NeuralNetTorch</td>\n",
              "      <td>-3.203236</td>\n",
              "      <td>0.008327</td>\n",
              "      <td>11.732957</td>\n",
              "      <td>0.008327</td>\n",
              "      <td>11.732957</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RandomForestMSE</td>\n",
              "      <td>-3.273199</td>\n",
              "      <td>0.076752</td>\n",
              "      <td>2.890948</td>\n",
              "      <td>0.076752</td>\n",
              "      <td>2.890948</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ExtraTreesMSE</td>\n",
              "      <td>-3.287109</td>\n",
              "      <td>0.066056</td>\n",
              "      <td>1.411693</td>\n",
              "      <td>0.066056</td>\n",
              "      <td>1.411693</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>KNeighborsUnif</td>\n",
              "      <td>-3.503884</td>\n",
              "      <td>0.168962</td>\n",
              "      <td>0.045144</td>\n",
              "      <td>0.168962</td>\n",
              "      <td>0.045144</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>KNeighborsDist</td>\n",
              "      <td>-3.571683</td>\n",
              "      <td>0.063752</td>\n",
              "      <td>0.028888</td>\n",
              "      <td>0.063752</td>\n",
              "      <td>0.028888</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  model  score_val  pred_time_val   fit_time  \\\n",
              "0   WeightedEnsemble_L2  -3.154248       0.101439  19.812445   \n",
              "1              CatBoost  -3.154663       0.001944   0.615816   \n",
              "2              LightGBM  -3.161942       0.001652   0.176849   \n",
              "3               XGBoost  -3.162130       0.004154   0.377868   \n",
              "4       NeuralNetFastAI  -3.168732       0.018366  15.781750   \n",
              "5            LightGBMXT  -3.171463       0.002525   0.572522   \n",
              "6         LightGBMLarge  -3.174114       0.001978   0.354304   \n",
              "7        NeuralNetTorch  -3.203236       0.008327  11.732957   \n",
              "8       RandomForestMSE  -3.273199       0.076752   2.890948   \n",
              "9         ExtraTreesMSE  -3.287109       0.066056   1.411693   \n",
              "10       KNeighborsUnif  -3.503884       0.168962   0.045144   \n",
              "11       KNeighborsDist  -3.571683       0.063752   0.028888   \n",
              "\n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                 0.000222           0.146062            2       True   \n",
              "1                 0.001944           0.615816            1       True   \n",
              "2                 0.001652           0.176849            1       True   \n",
              "3                 0.004154           0.377868            1       True   \n",
              "4                 0.018366          15.781750            1       True   \n",
              "5                 0.002525           0.572522            1       True   \n",
              "6                 0.001978           0.354304            1       True   \n",
              "7                 0.008327          11.732957            1       True   \n",
              "8                 0.076752           2.890948            1       True   \n",
              "9                 0.066056           1.411693            1       True   \n",
              "10                0.168962           0.045144            1       True   \n",
              "11                0.063752           0.028888            1       True   \n",
              "\n",
              "    fit_order  \n",
              "0          12  \n",
              "1           6  \n",
              "2           4  \n",
              "3           9  \n",
              "4           8  \n",
              "5           3  \n",
              "6          11  \n",
              "7          10  \n",
              "8           5  \n",
              "9           7  \n",
              "10          1  \n",
              "11          2  "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.leaderboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/hykhhijk/anaconda3/envs/ag/lib/python3.10/site-packages/catboost/core.py:1222: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  self._init_pool(data, label, cat_features, text_features, embedding_features, pairs, weight,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0    4.459158\n",
              "1    4.119506\n",
              "2    5.926070\n",
              "3    5.229726\n",
              "4    5.027195\n",
              "Name: label, dtype: float32"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = predictor.predict(test_x)\n",
        "y_pred.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5178,
        "step_number": 12,
        "trusted": true
      },
      "source": [
        "## **Submission 양식 확인**\n",
        "\n",
        "sample_submission.csv 화일 데이터(sample_submission)를 그대로 복사한 후, \n",
        "양식의 'ECLO' 컬럼에 test_x에 대한 ECLO(y) 예측값을 입력합니다 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5178,
        "step_number": 12,
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>ECLO</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ACCIDENT_39609</td>\n",
              "      <td>4.459158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ACCIDENT_39610</td>\n",
              "      <td>4.119506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ACCIDENT_39611</td>\n",
              "      <td>5.926070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ACCIDENT_39612</td>\n",
              "      <td>5.229726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACCIDENT_39613</td>\n",
              "      <td>5.027195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10958</th>\n",
              "      <td>ACCIDENT_50567</td>\n",
              "      <td>5.593705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10959</th>\n",
              "      <td>ACCIDENT_50568</td>\n",
              "      <td>4.927447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10960</th>\n",
              "      <td>ACCIDENT_50569</td>\n",
              "      <td>5.318663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10961</th>\n",
              "      <td>ACCIDENT_50570</td>\n",
              "      <td>5.268946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10962</th>\n",
              "      <td>ACCIDENT_50571</td>\n",
              "      <td>5.381470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10963 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ID      ECLO\n",
              "0      ACCIDENT_39609  4.459158\n",
              "1      ACCIDENT_39610  4.119506\n",
              "2      ACCIDENT_39611  5.926070\n",
              "3      ACCIDENT_39612  5.229726\n",
              "4      ACCIDENT_39613  5.027195\n",
              "...               ...       ...\n",
              "10958  ACCIDENT_50567  5.593705\n",
              "10959  ACCIDENT_50568  4.927447\n",
              "10960  ACCIDENT_50569  5.318663\n",
              "10961  ACCIDENT_50570  5.268946\n",
              "10962  ACCIDENT_50571  5.381470\n",
              "\n",
              "[10963 rows x 2 columns]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_submission = sample_submission.copy()\n",
        "baseline_submission['ECLO'] = prediction\n",
        "baseline_submission "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pbl_cell_type": "markdown",
        "step_id": 5178,
        "step_number": 12,
        "trusted": true
      },
      "source": [
        "## **답안지 저장 및 제출하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "pbl_cell_type": "code",
        "step_id": 5178,
        "step_number": 12,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "baseline_submission.to_csv('baseline_submit.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
